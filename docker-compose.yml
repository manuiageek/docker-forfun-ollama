services:
  ollama_gpu:
    image: ollama/ollama:latest
    container_name: ollama
    restart: always
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/data
    environment:
      - OLLAMA_BACKEND=nvidia
      - OLLAMA_MODELS=/data/models
      - OLLAMA_CONTEXT_LENGTH=3000
      - OLLAMA_KEEP_ALIVE=0
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_FLASH_ATTENTION=1
      - OLLAMA_KV_CACHE_TYPE=q8_0
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

volumes:
  ollama_data:
    external: true
